\documentclass[]{beamer}
% https://github.com/tbagrel1/latex_resources
\usepackage{tbagrelbeamer}
\usepackage{beamerstylebluesky}
\usepackage{pgfplots}

\newcommand{\btf}{\tt{brain\_tumor\_factory}}
\newcommand{\btn}{\tt{brain\_tumor\_nn}}
\newcommand{\btnt}{\tt{brain\_tumor\_nn2}}
\newcommand{\ca}[1]{\tt{\alert{#1}}}
\newcommand{\icdc}[1]{\alert{$\pm{}[$}#1\alert{$]$}}
\usetikzlibrary{fadings}

\begin{document}

\title{Deep learning}
\subtitle{CNN and supervised learning}
\author{March 2019 @ TELECOM Nancy\\T. \sc{Bagrel}}
\date{}

\begin{frame}
  \titlepage{}
\end{frame}

% \begin{frame}
%   \frametitle{}
%   \framesubtitle{}
% \end{frame}

\begin{frame}
  \frametitle{Introduction}
  \framesubtitle{Interesting NN architectures (supervised)}
  \begin{block}{\bf{C}onvolutional \bf{N}eural \bf{N}etwork (CNN)}
    \begin{itemize}
      \item \alert{Supervised \tt{:(}}
      \item Most common architecture for image processing
      \item Position-invariant feature extraction (with shared weights)
      \item Very efficient
    \end{itemize}
  \end{block}
\end{frame}
\begin{frame}
  \frametitle{Introduction}
  \framesubtitle{Interesting NN architectures (unsupervised)}
  \begin{block}{\bf{R}estricted \bf{B}oltzmann \bf{M}achine (RBM)}
    \begin{itemize}
      \item \alert{Unsupervised!}
      \item General feature extraction
      \item Basic block of \bf{D}eep \bf{B}elief \bf{N}etworks
    \end{itemize}
  \end{block}
  \begin{block}{\bf{A}uto\bf{e}ncoders (AE)}
    \begin{itemize}
      \item \alert{Unsupervised!}
      \item Can be used for denoising
      \item Can be used for general feature extraction
    \end{itemize}
  \end{block}
\end{frame}

\begin{frame}
  \frametitle{Autoencoders}
  \framesubtitle{Structure and principle}
  \begin{block}{Principle}
    \begin{itemize}
      \item \alert{Simple} : reproduce the input at the output
      \item \alert{How} : pass the input (image) through the NN, compute error from $\text{diff}(I, O)$, adjust weights with GD
    \end{itemize}
  \end{block}
  \begin{exampleblock}{Feature extraction}
    \alert{Bottleneck} : ``center'' of the NN where there is the lowest number of neurons. Activation in the ``bottleneck'' for a given input (image) represents its compressed form.
  \end{exampleblock}
\end{frame}

\begin{frame}
  \frametitle{Autoencoders}
  \framesubtitle{Denoising}
  \begin{center}
    \includegraphics[width=\linewidth]{resources/autoencoder}
    \captionof{figure}{Autoencoder with feature extraction purpose}
  \end{center}

  \begin{exampleblock}{Denoising}
    Denoising can be achieved with roughly the same architecture
  \end{exampleblock}

\end{frame}

\begin{frame}
  \frametitle{CNN Components}
  \framesubtitle{Gradient Descent}
  \begin{center}
    \includegraphics[width=\linewidth]{resources/perceptron}
    \captionof{figure}{Neuron (perceptron) schema}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{CNN Components}
  \framesubtitle{Gradient Descent}
  \begin{block}{Problem solved by GD}
    In which direction do we need to update our weights to minimize the error?
  \end{block}
  \begin{exampleblock}{Last layer neuron $n$ situation}
    $E$: error, $L$: loss function, $e$: expected value, $o$: obtained value, $\phi$: activation function, $x_{n, \cdot}$: inputs for the last layer neuron, $w_{n, \cdot}$: weights for the last layer neuron
    \begin{IEEEeqnarray}{rCl}
      E &=& L(e, o) \\
        &=& L\left(e,~~~\phi\left(\sum_k x_{n, k} w_{n, k}\right)\right)
    \end{IEEEeqnarray}
  \end{exampleblock}
\end{frame}

\begin{frame}
  \frametitle{CNN Components}
  \framesubtitle{Gradient Descent}
  \begin{exampleblock}{What we need to know}
    \begin{itemize}
      \item \alert{loss function} $L(e, o)$ and $\dfrac{\partial{}L}{\partial{o}}$
      \item \alert{activation function} $\phi(r)$ and $\dfrac{\mrm{d}\phi}{\mrm{d}r}$
    \end{itemize}
  \end{exampleblock}
  \begin{exampleblock}{What we can compute}
    With the \alert{chain rule}, we can compute $\dfrac{\partial{}E}{\partial{}w_{n, k}}(e, o) \quad (\forall k)$
  \end{exampleblock}
\end{frame}

\begin{frame}
  \frametitle{CNN Components}
  \framesubtitle{Gradient descent and adjustment made}
  \begin{block}{Weights adjustment ($\alpha$ : learning rate)}
    \[ w_{n, k} \longleftarrow w_{n, k} - \alpha \cdot \dfrac{\partial{}E}{\partial{}w_{n, k}}(e, o) \]
  \end{block}
  \begin{center}
    \includegraphics[width=0.8\linewidth]{resources/gd}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{CNN Components}
  \framesubtitle{Learning rate and advanced adjustment methods}
  \begin{center}
    \includegraphics[width=\linewidth]{resources/big_vs_small_lr}
    \captionof{figure}{Importance of an appropriate learning rate}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{CNN Components}
  \framesubtitle{Advanced adjustment methods}
  Called optimizers in \alert{TensorFlow}
  \begin{block}{Roles}
    \begin{itemize}
      \item Try to prevent staying in a non-global local minima during learning
      \item \alert{Examples} : Nesterov Momentum, Adam\ldots{}
    \end{itemize}
  \end{block}

  \begin{exampleblock}{Used in my NNs}
    I use Nesterov's momentum: \tt{optimizers.SGD(nesterov=True, momentum=M)}\\ because it's recommended on most tutorials
  \end{exampleblock}
\end{frame}

\begin{frame}
  \frametitle{CNN Components}
  \framesubtitle{GD vs SGD vs BGD}
  Each one is a different manner to apply Gradient Descent
  \begin{block}{Differences}
    \begin{itemize}
      \item \alert{(basic) Gradient Descent} : weights are updated after every epoch (whole dataset pass) $\to$ \alert{very costly} but more stable than SGD!
      \item \alert{Stochastic Gradient Descent} : weights are updated after \alert{every} sample $\to$ \alert{very fast}!
      \item \alert{Batch Gradient Descent} : weights are updated after $N$ samples ($10 \le N \le 100$: batch size) $\to$ \alert{best of both worlds!}
    \end{itemize}
  \end{block}
\end{frame}

\begin{frame}
  \frametitle{CNN Components}
  \framesubtitle{Convolutional layer}
  The (3D) \alert{dot product} between the \alert{filter weights} and an \alert{input image zone} of the same size/shape gives an activation value. Doing this operation for all possible image zones (with \bf{overlap}) gives the \alert{activation map} for this filter.

  \it{It explains the position invariance of feature extraction for CNNs!}
  \begin{center}
    \includegraphics[width=0.8\linewidth]{resources/conv_1}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{CNN Components}
  \framesubtitle{Convolutional layer}
  A \alert{convolutional layer} is composed of several filters, each one with its \alert{own weights}. Hence, the output of the convolutional layer is a \alert{stack of activation maps} (one for each filter)
  \begin{center}
    \includegraphics[width=0.8\linewidth]{resources/conv_2}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{CNN Components}
  \framesubtitle{Pooling layer}
  A \alert{pooling layer} is used to downsize/down-sample its input. \alert{All} the values in a zone of the input volume results in \alert{one} value in the output volume, by application of a simple function. Input zones \bf{must not overlap} here!

  A very common example is the \it{max pooling} 2 x 2:
  \begin{center}
    \includegraphics[width=\linewidth]{resources/pool}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{CNN Components}
  \framesubtitle{Output layer for classification}
  The output layer is used to extract classification information from a final dense/convolutional/pooling layer.
  \begin{block}{Types}
    \begin{itemize}
      \item For binary classification: Dense layer with \alert{sigmoid} activation function and \alert{1} neuron (1 output value)
      \item For multiclass classification : Dense layer with \alert{softmax} activation function and \alert{$\text{Nb}_{\text{classes}}$} neurons, followed by a $\text{arg\_max}(\cdot\cdot\cdot)$ function
    \end{itemize}
  \end{block}
\end{frame}

\begin{frame}
  \frametitle{CNN Components}
  \framesubtitle{Loss function for classification}
  \alert{Cross entropy} (aka. Negative Log Likelihood) is the loss function used in classification, which works well with the \alert{sigmoid} or \alert{softmax} activation functions (output layer)
  \begin{center}
    \includegraphics[width=0.7\linewidth]{resources/nll}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{CNN Components}
  \framesubtitle{CNN schema for multiclass}
  \begin{center}
    \includegraphics[width=\linewidth]{resources/cnn_schema}
    \captionof{figure}{CNN architecture}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{Medical imaging}
  \framesubtitle{Availability}
  \begin{block}{The issue}
    There are medical image datasets available online, but
    \begin{itemize}
      \item \alert{High resolution}
      \item Difficult to find the differencies or the good class for an \alert{untrained eye}
      \item File format and dataset organisation is not always \alert{normalized}
    \end{itemize}
  \end{block}
  \begin{exampleblock}{Examples}
    \begin{itemize}
      \item \alert{List of public datasets}: \url{bit.ly/2EOziVp}, \url{bit.ly/2u0Da0Q}
      \item \alert{Datasets}: \url{bit.ly/2F34jqb} (cancer cells), \url{bit.ly/2u99w9L} (neuroimaging), \url{bit.ly/2cGnNQL} (Alzheimer)\ldots{}
    \end{itemize}
  \end{exampleblock}
\end{frame}

\begin{frame}
  \frametitle{Medical imaging}
  \framesubtitle{What to do so?}
  \begin{block}{Requirements}
    \begin{itemize}
      \item Large dataset
      \item Low-res images (max. 256 x 256)
      \item Something which looks like medical images
    \end{itemize}
  \end{block}
  \begin{exampleblock}{Idea}
    Generate \alert{brain 2D images} and add random ``tumors'' on them
  \end{exampleblock}
  \begin{center}
    \includegraphics[width=1.8cm]{resources/brain_base}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{\btf}
  \framesubtitle{Let's get our hands dirty!}
  \begin{block}{How to generate?}
    Home-made C program: \alert{\btf}
    \begin{itemize}
      \item take a \alert{single} base image
      \item add tumor(s) randomly depending on the chosen scenario
      \item alter the resulting image, to ensure that each output image is a bit unique
    \end{itemize}
    Program size: $\simeq$ 500 LOC

    Output: $\simeq$ 1000 images/s

    Image size: \alert{96 x 128 x 1} (grayscale)
  \end{block}
\end{frame}

\tikzfading[name=fade out, inner color=transparent!0,
  outer color=transparent!100]

\begin{frame}[fragile]
  \frametitle{\btf}
  \framesubtitle{Creating tumors: \tt{tumor} function}
  \begin{block}{Instructions}
    Take a cirle of radius $R_{\text{area}}$, and put $n \in \itg{n_{\text{min}}, n_{\text{max}}}$ ``soft discs'' of radius $r_i \in [r_{\text{min}}, r_{\text{max}}]$ with their center placed randomly inside the chosen area
  \end{block}
  \begin{center}
    \begin{tikzpicture}[scale=0.5]
      \draw (0, 0) circle (4cm);
      \fill[path fading=fade out, color=alertTextColor] (0.3, 0.4) circle (3cm);
      \fill[path fading=fade out, color=alertTextColor] (2.3, -1.9) circle (1.75cm);
      \fill[path fading=fade out, color=alertTextColor] (-1.2, 2.54) circle (2.22cm);
      \fill[path fading=fade out, color=alertTextColor] (-0.98, -1.44) circle (1.48cm);
    \end{tikzpicture}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{\btf}
  \framesubtitle{Altering the resulting image: \tt{alter\_full} function}
  \begin{block}{Alterations}
    \begin{itemize}
      \item \ca{shrink}: shrink the image on x-axis and/or y-axis
      \item \ca{move}: shift the image on x-axis and/or y-axis
      \item (\ca{ghost\_blur~\tss{0.1\%}}): simulate motion blur on a shot
      \item \ca{alter\_contrast}: \icdc{brightness range}, with custom ``brightness center''
      \item \ca{alter\_shade}: global flat \icdc{brightness}
      \item \ca{alter\_rdc}: per-pixel flat random \icdc{brightness}
    \end{itemize}
  \end{block}

  For each image, alterations parameters are random numbers taken from a \alert{uniform} or \alert{normal} distribution
\end{frame}

\begin{frame}
  \frametitle{\btf}
  \framesubtitle{Base image}
  \begin{center}
    \includegraphics[width=5.5cm]{resources/brain_base}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{\btf}
  \framesubtitle{Altered images}
  \begin{minipage}{\linewidth}
    \begin{center}
      \includegraphics[width=2.55cm]{resources/z1}
      \includegraphics[width=2.55cm]{resources/z2}
      \includegraphics[width=2.55cm]{resources/z3}
      \includegraphics[width=2.55cm]{resources/z4}
    \end{center}
  \end{minipage}
  \begin{minipage}{\linewidth}
    \begin{center}
      \includegraphics[width=2.55cm]{resources/z5}
      \includegraphics[width=2.55cm]{resources/z6}
      \includegraphics[width=2.55cm]{resources/z7}
      \includegraphics[width=2.55cm]{resources/z8}
    \end{center}
  \end{minipage}
\end{frame}

\begin{frame}
  \frametitle{\btf}
  \framesubtitle{Syndrome A}
  \begin{block}{Description}
    \begin{itemize}
      \item \alert{$\itg{1, 2}$} big tumor(s)
      \item \alert{$\itg{0, 2}$} medium tumor(s)
    \end{itemize}
  \end{block}
  \begin{center}
    \includegraphics[width=3.2cm]{resources/a1e}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{\btf}
  \framesubtitle{Syndrome B}
  \begin{block}{Description}
    \begin{itemize}
      \item \alert{$\itg{4, 8}$} medium tumor(s)
      \item \alert{$\itg{0, 3}$} small/tiny tumor(s)
    \end{itemize}
  \end{block}
  \begin{center}
    \includegraphics[width=3.2cm]{resources/b1e}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{\btf}
  \framesubtitle{Syndrome C}
  \begin{block}{Description}
    \begin{itemize}
      \item only \alert{$\itg{20, 48}$} small/tiny tumor(s)
    \end{itemize}
  \end{block}
  \begin{center}
    \includegraphics[width=3.2cm]{resources/c1e}
  \end{center}
\end{frame}

\begin{frame}
  \frametitle{\btf}
  \framesubtitle{Guess game: EASY mode}
  \begin{minipage}{\linewidth}
    \begin{center}
      \includegraphics[width=2.55cm]{resources/b2e}
      \includegraphics[width=2.55cm]{resources/z1e}
      \includegraphics[width=2.55cm]{resources/a2e}
      \includegraphics[width=2.55cm]{resources/z3e}
    \end{center}
  \end{minipage}
  \begin{minipage}{\linewidth}
    \begin{center}
      \includegraphics[width=2.55cm]{resources/b4e}
      \includegraphics[width=2.55cm]{resources/c2e}
      \includegraphics[width=2.55cm]{resources/c3e}
      \includegraphics[width=2.55cm]{resources/a4e}
    \end{center}
  \end{minipage}
\end{frame}

\begin{frame}
  \frametitle{\btf}
  \framesubtitle{Guess game: HARD mode}
  \begin{block}{Observation}
    It turns out that it's kinda easy to find the correct syndrome type, isn't it?

    Let's try the \alert{HARD} mode then (more realistic) \includegraphics[height=12pt]{resources/devil}
  \end{block}

  \begin{exampleblock}{HARD mode specifications}
    \begin{itemize}
      \item Tumor opacity \alert{greatly} reduced
      \item Tumor size reduced a bit
    \end{itemize}
  \end{exampleblock}

  The \alert{base image} will always be placed on the \alert{LEFT} of the image whose type must be determined
\end{frame}

\begin{frame}
  \frametitle{\btf}
  \framesubtitle{Guess game: HARD mode}
  \begin{minipage}{\linewidth}
    \begin{center}
      \includegraphics[width=4.2cm]{resources/brain_base}
      \includegraphics[width=4.2cm]{resources/c2}
    \end{center}
  \end{minipage}
  \pause
  \begin{block}{Answer}
    Syndrome C
  \end{block}
\end{frame}

\begin{frame}
  \frametitle{\btf}
  \framesubtitle{Guess game: HARD mode}
  \begin{minipage}{\linewidth}
    \begin{center}
      \includegraphics[width=4.2cm]{resources/brain_base}
      \includegraphics[width=4.2cm]{resources/a2}
    \end{center}
  \end{minipage}
  \pause
  \begin{block}{Answer}
    Syndrome A
  \end{block}
\end{frame}

\begin{frame}
  \frametitle{\btf}
  \framesubtitle{Guess game: HARD mode}
  \begin{minipage}{\linewidth}
    \begin{center}
      \includegraphics[width=4.2cm]{resources/brain_base}
      \includegraphics[width=4.2cm]{resources/z3}
    \end{center}
  \end{minipage}
  \pause
  \begin{block}{Answer}
    Z (healthy patient)
  \end{block}
\end{frame}

\begin{frame}
  \frametitle{\btf}
  \framesubtitle{Guess game: HARD mode}
  \begin{minipage}{\linewidth}
    \begin{center}
      \includegraphics[width=4.2cm]{resources/brain_base}
      \includegraphics[width=4.2cm]{resources/b2}
    \end{center}
  \end{minipage}
  \pause
  \begin{block}{Answer}
    Syndrome B
  \end{block}
\end{frame}

\begin{frame}
  \frametitle{\btf}
  \framesubtitle{Guess game: HARD mode}
  \begin{minipage}{\linewidth}
    \begin{center}
      \includegraphics[width=4.2cm]{resources/brain_base}
      \includegraphics[width=4.2cm]{resources/z4}
    \end{center}
  \end{minipage}
  \pause
  \begin{block}{Answer}
    Z (healthy patient)
  \end{block}
\end{frame}

\begin{frame}
  \frametitle{\btf}
  \framesubtitle{Guess game: HARD mode}
  \begin{minipage}{\linewidth}
    \begin{center}
      \includegraphics[width=4.2cm]{resources/brain_base}
      \includegraphics[width=4.2cm]{resources/c3}
    \end{center}
  \end{minipage}
  \pause
  \begin{block}{Answer}
    Syndrome C
  \end{block}
\end{frame}

\begin{frame}
  \frametitle{\btf}
  \framesubtitle{Guess game: HARD mode}
  \begin{block}{Observation}
    Not so easy this time? \includegraphics[height=12pt]{resources/devil}
  \end{block}

  \vfill

  \begin{center}
    \Large
    Let's see what \alert{deep learning} can do
  \end{center}

  \vfill
\end{frame}

\begin{frame}
  \frametitle{\btn}
  \framesubtitle{Description}
  \begin{block}{Framework}
    \begin{itemize}
      \item DL4j / ScalNet (Scala)
      \item not really fast (afterwards)
      \item Keras-like API
    \end{itemize}
  \end{block}
  \begin{exampleblock}{Architecture}
    \begin{itemize}
      \item 3 \tt{Conv2D} (\tt{MaxPooling2D} inbetween): 16 64 256
      \item \tt{Dense} 1024
      \item GD (BGD) with Nesterov Momentum
      \item (adapted from MNIST NN examples)
    \end{itemize}
  \end{exampleblock}
\end{frame}

\begin{frame}
  \frametitle{\btn}
  \framesubtitle{Description}
  \begin{block}{Issue (after 2 hours learning)}
    \begin{itemize}
      \item Accuracy blocked at 0.25
      \item loss wasn't decreasing
      \item a \alert{single type} predicted everytime
    \end{itemize}
  \end{block}
  \begin{exampleblock}{Why (afterwards)}
    \begin{itemize}
      \item I didn't wait long enough (on hard samples)
      \item 3 Conv layer NN + slow framework didn't help much neither
      \item in addition, learning on mobile CPU (i7) is still slow
      \item (but afterwards) architecture wasn't really the issue
    \end{itemize}
  \end{exampleblock}
\end{frame}

\begin{frame}
  \frametitle{\btnt}
  \framesubtitle{Description}

  \begin{block}{Framework}
    \begin{itemize}
      \item Tensorflow with Keras
      \item Learning on CPU and then on GPU
    \end{itemize}
  \end{block}

  \begin{exampleblock}{Architecture}
    \begin{itemize}
      \item Simplified architecture first: only 2 \tt{Conv2D} layers
      \item Learning on \alert{EASY} images first
    \end{itemize}
  \end{exampleblock}

  Dataset: 100~000 L / 10~000 T \alert{EASY} images

  Very good results: \alert{97-99 \% acc} after 4 epochs (CPU)
\end{frame}

\begin{frame}
  \frametitle{\btnt}
  \framesubtitle{Training on HARD dataset (v1)}

  \begin{exampleblock}{Architecture (v1)}
    2 \tt{Conv2D} (64 128) + 1 \tt{Dense} (1024)
  \end{exampleblock}

  Dataset: 100~000 L / 10~000 T \alert{HARD} images

  Learning: \alert{GPU} now, about 30x faster ($\simeq$ 1 min/epoch)

  Encouraging results: over \alert{80 \% acc} after an hour, but \alert{overfitting} at the end: about \alert{100 \% acc} on train data

  \medskip

  Final score on test data: \alert{90 \% acc}
\end{frame}

\begin{frame}
  \frametitle{\btnt}
  \framesubtitle{Training on HARD dataset (v2)}

  Smaller network, for faster convergence, and to reduce overfitting

  \begin{exampleblock}{Architecture (v2)}
    2 \tt{Conv2D} (32 64) + 1 \tt{Dense} (512)
  \end{exampleblock}

  Good results: more than \alert{84 \% acc} after a few epochs, but still \alert{overfitting} at the end: about \alert{100 \% acc} on train data

  \medskip

  Final score on test data: \alert{90 \% acc}
\end{frame}

\begin{frame}
  \frametitle{\btnt}
  \framesubtitle{Training on HARD dataset (v3)}

  Even smaller network, in order to reduce overfitting again

  \begin{exampleblock}{Architecture (v3)}
    2 \tt{Conv2D} (16 32) + 1 \tt{Dense} (256)
  \end{exampleblock}

  Good results: more than \alert{86 \% acc} after a few epochs, but still \alert{overfitting}: about \alert{100 \% acc} on train data

  \medskip

  Final score on test data: \alert{90 \% acc}
\end{frame}

\begin{frame}
  \frametitle{Issues}
  \framesubtitle{Overfitting}

  \begin{block}{Description}
    Overfitting: when the model learns more the specificities of the train dataset samples (\it{ie} noise) than the general features of them (which are shared with the test dataset)
  \end{block}

  \begin{alertblock}{Causes}
    Too many free parameters, too few different training samples
  \end{alertblock}

  \begin{exampleblock}{How to counter it?}
    Regularization is kinda effective
  \end{exampleblock}
\end{frame}

\begin{frame}
  \frametitle{Issues}
  \framesubtitle{Overfitting}
  \begin{center}
    \includegraphics[width=\linewidth]{resources/overfitting}
  \end{center}
  \captionof{figure}{Memorizing is not learning!}
\end{frame}

\begin{frame}
  \frametitle{Solutions}
  \framesubtitle{Regularization}

  \begin{block}{General idea}
    Regularization: penalize the model when weights are high (decrease ``freedom'' of the model)
  \end{block}

  \begin{exampleblock}{Consequences}
    \begin{itemize}
      \item Counters overfitting (accuracy on test dataset will be closer to the accuracy on train dataset)
      \item \alert{BUT} too much regularization can lead to \alert{underfitting}!
    \end{itemize}
  \end{exampleblock}
\end{frame}

\begin{frame}
  \frametitle{Issues}
  \framesubtitle{Underfitting}

  \begin{block}{Description}
    Underfitting: when there's not enough free parameters/freedom to learn the datasets (both training and testing)
  \end{block}

  \begin{exampleblock}{How to counter it?}
    \begin{itemize}
      \item Reduce regularization factor
      \item Add parameters (extend the model)
    \end{itemize}
  \end{exampleblock}
\end{frame}

\begin{frame}
  \frametitle{Issues}
  \framesubtitle{Underfitting}
  \begin{center}
    \includegraphics[width=\linewidth]{resources/underfitting}
  \end{center}
  \captionof{figure}{Balance is the key here}
\end{frame}

\begin{frame}
  \frametitle{\btnt}
  \framesubtitle{Training on HARD dataset (v4)}

  Same architecture as v2, with regularization: \alert{L2(0.001)}

  \begin{exampleblock}{Architecture (v4)}
    2 \tt{Conv2D} (32 64) + 1 \tt{Dense} (512) \hfill \alert{L2(0.001)}
  \end{exampleblock}

  Good results: over \alert{89 \% acc} on test data after an hour of training, but \alert{underfitting}: acc on training dataset no longer improves (blocked at \alert{96 \% acc})

  \medskip

  Final score on test data: \alert{91 \% acc}
\end{frame}

\begin{frame}
  \frametitle{\btnt}
  \framesubtitle{Training on HARD dataset (v5)}

  Larger model than v4, with less regularization: \alert{L2(0.0005)}

  \begin{exampleblock}{Architecture (v5)}
    2 \tt{Conv2D} (64 128) + 1 \tt{Dense} (1024) \hfill \alert{L2(0.0005)}
  \end{exampleblock}

  Very good results: over \alert{91 \% acc} on test data after an hour of training!

  \medskip

  Final score on test data: \alert{93 \% acc}
  \bigskip

  Let's try adding \alert{more layers} now!
\end{frame}

\begin{frame}
  \frametitle{\btnt}
  \framesubtitle{Training on HARD dataset (v6)}

  One more conv layer than v5

  \begin{exampleblock}{Architecture (v6)}
    3 \tt{Conv2D} (32 64 128) + 1 \tt{Dense} (1024) \hfill \alert{L2(0.0005)}
  \end{exampleblock}

  Very good results: over \alert{95 \% acc} on test data after an hour of training!

  \medskip

  Final score on test data: \alert{96 \% acc}

  \bigskip

  One \alert{more layer}? Why not!
\end{frame}

\begin{frame}
  \frametitle{\btnt}
  \framesubtitle{Training on HARD dataset (v7)}

  One more conv layer than v6

  \begin{exampleblock}{Architecture (v7)}
    4 \tt{Conv2D} (16 32 64 128) + 1 \tt{Dense} (1024) \hfill \alert{L2(0.0005)}
  \end{exampleblock}

  Still very good results, but not improving\ldots{}

  \medskip

  Final score on test data: \alert{95 \% acc}

  \bigskip

  What should we do now?
\end{frame}

\begin{frame}
  \frametitle{\btnt}
  \framesubtitle{Training in HARD dataset (v8 \& v9)}
  \begin{exampleblock}{Architecture (v8) -- the stupid one}
    4 \tt{Conv2D} (16 32 64 256) + 1 \tt{Dense} (2048) \hfill \alert{L2(0.0001)}
  \end{exampleblock}
  \alert{Overfitting} again, worse than v7 (not a good move\ldots{})

  \bigskip

  But the (final) v9 architecture gave the \alert{best results}!
  \begin{itemize}
    \item 2x more filters for each conv layer
    \item same regularization as v7
  \end{itemize}

  \begin{exampleblock}{Architecture (v9)}
    4 \tt{Conv2D} (32 64 128 256) + 1 \tt{Dense} (1024) \hfill \alert{L2(0.0005)}
  \end{exampleblock}

  Final results on test data: more than \alert{97 \% acc}!
\end{frame}

\begin{frame}
  \frametitle{\btnt}
  \framesubtitle{Conclusions}
  \begin{itemize}
    \item The \alert{simplest} $\lto$ \alert{most complex} approach paid off
    \item It was much easier to reason about the NN when the learning time was very short (with GPU)
    \item Each model was trained about \alert{3 hours} (equiv. $\simeq$ 4 days on CPU)
  \end{itemize}

  \begin{block}{Key points}
    \begin{itemize}
      \item Learning can be disappointing at first (the 3 firsts epochs in my case), with just one class predicted for example
      \item Computer can outperform Human on classification with a decent amount of learning
    \end{itemize}
  \end{block}
\end{frame}

\begin{frame}
  \frametitle{\btnt}
  \framesubtitle{Bias towards test data}
  \begin{block}{Problem}
    Even if the model doesn't learn directly from the test dataset, the \tt{save\_best} approach introduces a sort of ``indirect learning'' from the test dataset
  \end{block}

  \begin{exampleblock}{Solution (not implemented here)}
    Use a 3\tss{rd} dataset for the final comparison between models, called \alert{validation dataset}
  \end{exampleblock}
\end{frame}

\begin{frame}
  \frametitle{CNN IRL}
  \framesubtitle{Real world examples and dataset augmentation}
  The \alert{\btf} was useful because I had:
  \begin{itemize}
    \item a normalized dataset
    \item as many samples as I wanted
  \end{itemize}

  But this is not often the case in real life examples

  \begin{exampleblock}{Solution}
    Use dataset augmentation, which generates new samples from the real ones, by rotating, resizing\ldots{}
  \end{exampleblock}
\end{frame}

\begin{frame}
  \frametitle{Credits}
  \framesubtitle{Thanks for listening!}

  \begin{block}{Sources}
    \begin{itemize}
      \item \url{https://oreil.ly/2TLLnUM}
      \item \url{https://bit.ly/2F3exFV}
      \item \url{https://bit.ly/2XSh5Pr}
      \item \url{https://bit.ly/2Ces8to}
      \item \url{https://bit.ly/2NWh0pA}
      \item \url{https://bit.ly/2J8zOmA}
      \item \url{https://bit.ly/2LsZNBM}
      \item \url{https://bit.ly/2VUuK73}
      \item \url{https://bit.ly/2UvlA0j}
    \end{itemize}
  \end{block}
\end{frame}

\end{document}
